<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quality Prompts</title>
    <link rel="stylesheet" href="./css/styles.css">
    <link rel="stylesheet" href="./css/components.css">
    <link rel="icon" type="image/svg+xml" href="./assets/favicon.svg">
    <script src="https://js.puter.com/v2/"></script>
</head>
<body>
    <h1>Quality Prompts</h1>
    <p class="subtitle">Transform simple ideas into production-ready prompts</p>
    <div class="how-to-use-row">
        <button id="btn-info" class="btn-how-to-use">How to use</button>
    </div>

    <!-- Info Modal -->
    <div id="info-modal" class="modal-overlay hidden">
        <div class="modal">
            <div class="modal-header">
                <h3>About Quality Prompts</h3>
                <button id="btn-close-info" class="btn-modal-close">&times;</button>
            </div>
            <div class="modal-body">
                <p><strong>Quality Prompts</strong> is a free, serverless tool that transforms simple ideas into high-quality, production-ready prompts. You provide a short description of what you want, and the tool builds a detailed, structured prompt for you. It adds objectives, constraints, deliverables, evaluation criteria, and edge case handling automatically.</p>

                <h4>How it works</h4>
                <p>Select a subject type, then optionally choose a prompt style to tailor the output for a specific workflow. Choose a target model class to optimize prompt length and complexity. Type a short idea into the text field, a sentence or two is ideal. Click Generate Prompt and the tool returns your optimized prompt in three formats: Plain Text for copy-pasting, Structured with markdown, and JSON for agents and APIs.</p>

                <h4>Prompt styles</h4>
                <p>Every subject type has specialized prompt styles that adapt the generated prompt for different workflows. When you select a subject type, the Prompt Style dropdown appears with options tailored to that category. Select General to use the default dimensions without a specific style.</p>

                <p><strong>Development</strong> — Specification Prompt for new projects with no prior context. Iteration Prompt for targeted changes to existing code. Diagnostic Prompt for debugging unknown failures.</p>

                <p><strong>Writing</strong> — Creative Writing (Long-Form) for essays, articles, and narrative work. Short-Form Copy for ads, taglines, and microcopy. Marketing Communications for emails, newsletters, and press releases.</p>

                <p><strong>Strategy</strong> — Business Strategy for competitive positioning and growth planning. Go-to-Market Strategy for launch plans and pricing. Technical Strategy for architecture decisions and technology selection.</p>

                <p><strong>Product</strong> — Product Requirements Document for full PRDs with acceptance criteria. User Stories for sprint-ready stories in standard format. Feature Specification for detailed single-feature specs covering all states.</p>

                <p><strong>Design</strong> — UI/UX Design for wireframes, flows, and component specs. Design Assets for logos, icons, and visual elements. Photo Editing for image modification and compositing instructions.</p>

                <p><strong>Marketing</strong> — Campaign Planning for multi-channel campaigns with budgets and KPIs. Content Strategy for editorial calendars and content pillars. Social Media for platform-specific strategies and posts.</p>

                <p><strong>Research</strong> — Literature Review for systematic source synthesis and gap analysis. User Research for interview guides, surveys, and usability studies. Market Research for competitive analysis and market sizing.</p>

                <p><strong>Data Analysis</strong> — Exploratory Analysis for data profiling and pattern discovery. Dashboard &amp; Reporting for KPI dashboards with metric definitions. Statistical Modeling for regression, hypothesis testing, and model validation.</p>

                <h4>API providers</h4>
                <p>Quality Prompts supports multiple API providers. Select your provider in the API Settings panel and enter your API key.</p>
                <p><strong>Puter GPT-OSS</strong> is the default and is completely free with no API key required. It uses Puter's user-pays model, which means you as a developer or site owner pay nothing. Instead, each person who uses the tool covers their own AI inference cost through their Puter account. When a user first triggers an AI request, Puter handles authentication automatically. Users get a free usage allowance, and any usage beyond that is billed to their own Puter account, not yours. This means the tool can scale to unlimited users at zero cost to the host. The gpt-oss-120b model (117B parameters) produces the best results but is slower. The gpt-oss-20b model (21B parameters) is faster with lower quality. Both are open-weight models from OpenAI running on Puter's infrastructure.</p>
                <p><strong>OpenRouter</strong> is recommended for users who want access to hundreds of models (Claude, GPT, Gemini, Llama, Mistral, and more) through a single API key. It is CORS-friendly and works directly in the browser without a proxy. Get a key at openrouter.ai/keys.</p>
                <p><strong>Anthropic</strong> connects directly to the Claude Messages API. Get a key at console.anthropic.com.</p>
                <p><strong>OpenAI</strong> connects to the Chat Completions API. Get a key at platform.openai.com.</p>
                <p><strong>Google Gemini</strong> connects to the Gemini API. Get a key at aistudio.google.com.</p>
                <p><strong>Ollama</strong> runs AI models locally on your machine. No API key needed, no data leaves your computer, completely free. Select Ollama (Local) as the provider, make sure Ollama is running with CORS enabled (<code>OLLAMA_ORIGINS=* ollama serve</code>), and enter the model name you've pulled. Click Setup Instructions in the Ollama settings for a full guide.</p>
                <p><strong>Custom Endpoint</strong> supports any OpenAI-compatible API including Together, LM Studio, and other self-hosted models. Enter your base URL and it uses the /chat/completions format with Bearer token auth.</p>

                <h4>Tips for best results</h4>
                <p>Keep your idea brief. The whole point of this tool is to do the heavy lifting for you, so you do not need to write a full prompt yourself. Focus on what you want accomplished, not on how to prompt for it. The more specific your idea is, the better the output will be. For example, "build a dashboard that tracks user retention by cohort" will produce a much better prompt than just "build a dashboard."</p>

                <h4>Sharing and using your prompt</h4>
                <p>The <strong>Share Idea</strong> button (above Generate Prompt) opens a modal where you can copy a prefilled URL of your idea. Choose "Copy link" to share a URL that prefills the idea for the recipient, or "Copy link with auto-generate" to share a URL that also triggers prompt generation automatically when opened.</p>

                <p>Once a prompt is generated, the <strong>Use this prompt</strong> section at the bottom lets you open the generated prompt directly in ChatGPT, Claude, Copilot, or Gemini. ChatGPT receives the prompt automatically. For Claude, Copilot, and Gemini, the prompt is copied to your clipboard and the service opens in a new tab — just paste it when the page loads.</p>

                <p>You can also <strong>Share via Email</strong> from the Plain Text tab to send the full generated prompt by email.</p>

                <h4>Output formats</h4>
                <p>The Plain Text tab gives you a clean, readable prompt you can paste directly into any chat interface. The Structured tab formats the same prompt with markdown headings, sections, and bullet points for easy scanning. The JSON tab provides a programmatic format with separate fields for system instructions, user prompts, constraints, and evaluation criteria, which is useful for agents and API integrations.</p>

                <h4>URL routing</h4>
                <p>You can prefill the idea input via URL. Add <code>?prompt=your idea here</code> to the URL to prefill, or add <code>&amp;enter</code> to also auto-generate the prompt on page load. The bare format <code>?=your idea here</code> also works. This is useful for bookmarks, integrations, and the Share Idea feature.</p>

                <p>All processing happens through the selected API provider. No data is stored on any server.</p>
            </div>
        </div>
    </div>

    <div id="file-protocol-warning" class="warning-banner hidden">
        <strong>Local file detected.</strong> The Puter API requires a web server. Run this from your project folder:
        <code>python3 -m http.server 8000</code> then open <a href="http://localhost:8000">http://localhost:8000</a>
    </div>

    <div class="container">
        <!-- Settings Panel -->
        <button id="settings-toggle" class="settings-toggle">&#9654; API Settings</button>
        <div id="settings-panel" class="settings-panel hidden">
            <div class="form-group">
                <label for="api-mode">API Provider</label>
                <select id="api-mode">
                    <option value="puter">Puter GPT-OSS (Free, no key required)</option>
                    <option value="openrouter">OpenRouter (CORS-friendly, many models)</option>
                    <option value="anthropic">Anthropic Claude</option>
                    <option value="openai">OpenAI</option>
                    <option value="google">Google Gemini</option>
                    <option value="ollama">Ollama (Local)</option>
                    <option value="custom">Custom Endpoint</option>
                </select>
            </div>

            <!-- Puter Settings (no key needed) -->
            <div id="puter-settings" class="provider-settings">
                <div class="form-group">
                    <label for="puter-model">Model</label>
                    <select id="puter-model">
                        <option value="openai/gpt-oss-120b">gpt-oss-120b (117B params, best quality)</option>
                        <option value="openai/gpt-oss-120b:exacto">gpt-oss-120b:exacto (precise variant)</option>
                        <option value="openai/gpt-oss-20b">gpt-oss-20b (21B params, faster)</option>
                    </select>
                </div>
                <p class="settings-hint">Powered by Puter.com — free, no API key needed.</p>
            </div>

            <!-- Ollama Settings (local, no key needed) -->
            <div id="ollama-settings" class="provider-settings hidden">
                <div class="form-group">
                    <label for="ollama-url">Ollama URL</label>
                    <input type="text" id="ollama-url" value="http://localhost:11434" placeholder="http://localhost:11434">
                </div>
                <div class="form-group">
                    <label for="ollama-model">Model</label>
                    <input type="text" id="ollama-model" placeholder="llama3.2" value="llama3.2">
                </div>
                <div class="ollama-hint-row">
                    <p class="settings-hint">Runs locally on your machine — no API key, no data leaves your computer.</p>
                    <button type="button" id="btn-ollama-help" class="btn-small">Setup Instructions</button>
                </div>
            </div>

            <!-- Ollama Instructions Modal -->
            <div id="ollama-modal" class="modal-overlay hidden">
                <div class="modal">
                    <div class="modal-header">
                        <h3>Running Quality Prompts with Ollama</h3>
                        <button id="btn-close-ollama" class="btn-modal-close">&times;</button>
                    </div>
                    <div class="modal-body">
                        <p>Ollama lets you run AI models locally on your own machine. No API key needed, no data leaves your computer, and it's completely free.</p>

                        <h4>1. Install Ollama</h4>
                        <p>Download and install from <strong>ollama.com</strong>. Available for macOS, Linux, and Windows.</p>

                        <h4>2. Pull a model</h4>
                        <p>Open your terminal and run:</p>
                        <pre style="background:#1e1e1e;color:#d4d4d4;padding:12px;border-radius:6px;font-size:13px;">ollama pull llama3.2</pre>
                        <p>Other recommended models for prompt generation:</p>
                        <ul>
                            <li><strong>llama3.2</strong> — 3B params, fast, good for most tasks</li>
                            <li><strong>llama3.1:8b</strong> — 8B params, better quality</li>
                            <li><strong>mistral</strong> — 7B params, strong instruction following</li>
                            <li><strong>qwen2.5:14b</strong> — 14B params, excellent for structured output</li>
                            <li><strong>gemma2:9b</strong> — 9B params, good balance of speed and quality</li>
                        </ul>

                        <h4>3. Start Ollama with CORS enabled</h4>
                        <p>Quality Prompts runs in your browser, so Ollama needs to allow cross-origin requests. Start it with:</p>
                        <pre style="background:#1e1e1e;color:#d4d4d4;padding:12px;border-radius:6px;font-size:13px;">OLLAMA_ORIGINS=* ollama serve</pre>
                        <p>On Windows (PowerShell):</p>
                        <pre style="background:#1e1e1e;color:#d4d4d4;padding:12px;border-radius:6px;font-size:13px;">$env:OLLAMA_ORIGINS="*"; ollama serve</pre>
                        <p>If Ollama is already running (e.g. the desktop app), you'll need to stop it first and restart with the CORS flag, or set the environment variable permanently.</p>

                        <h4>4. Configure Quality Prompts</h4>
                        <ol>
                            <li>Select <strong>Ollama (Local)</strong> as the API Provider</li>
                            <li>The URL defaults to <strong>http://localhost:11434</strong> — change it if you're using a different port</li>
                            <li>Enter the model name you pulled (e.g. <strong>llama3.2</strong>)</li>
                            <li>Click <strong>Generate Prompt</strong></li>
                        </ol>

                        <h4>Troubleshooting</h4>
                        <p><strong>CORS error / Failed to fetch:</strong> Make sure Ollama is running with <code>OLLAMA_ORIGINS=*</code>. The default Ollama server blocks browser requests without this.</p>
                        <p><strong>Connection refused:</strong> Make sure Ollama is running (<code>ollama serve</code>) and check that the URL and port are correct.</p>
                        <p><strong>Model not found:</strong> Run <code>ollama list</code> to see installed models, and make sure the model name matches exactly.</p>
                    </div>
                </div>
            </div>

            <!-- Shared fields for all key-based providers -->
            <div id="keyed-settings" class="provider-settings hidden">
                <div class="form-group">
                    <label for="api-key">API Key</label>
                    <input type="password" id="api-key" placeholder="sk-...">
                </div>
                <div id="base-url-group" class="form-group hidden">
                    <label for="base-url">Base URL</label>
                    <input type="text" id="base-url" placeholder="https://api.openai.com/v1">
                </div>
                <div class="form-group">
                    <label for="model-name">Model</label>
                    <input type="text" id="model-name" placeholder="gpt-4o">
                </div>
                <div class="checkbox-group">
                    <input type="checkbox" id="save-key">
                    <label for="save-key">Remember settings in this browser</label>
                </div>
                <p id="provider-hint" class="settings-hint"></p>
            </div>
        </div>

        <hr class="section-divider">

        <!-- Input Section -->
        <div class="form-row">
            <div class="form-group">
                <label for="subject-type">Subject Type</label>
                <select id="subject-type"></select>
            </div>
            <div class="form-group" id="sub-type-group" style="display: none;">
                <label for="sub-type">Prompt Style</label>
                <select id="sub-type">
                    <option value="">General</option>
                </select>
            </div>
            <div class="form-group">
                <label for="model-type">Target Model</label>
                <select id="model-type"></select>
            </div>
        </div>

        <div class="form-group">
            <label for="idea-input">Your Idea</label>
            <textarea id="idea-input" maxlength="1500" placeholder="Keep it short, a sentence or two is ideal. The tool builds the full prompt for you." rows="3"></textarea>
            <div class="char-counter"><span id="char-count">0</span> / 1,500 characters</div>
            <div id="char-limit-hint" class="char-limit-hint hidden">You're at the limit. Remember, the point of this tool is to build the detailed prompt for you — just describe your idea briefly and let Quality Prompts do the rest.</div>
        </div>

        <div id="share-idea-row" class="share-idea-row">
            <button id="btn-share-idea" class="btn-small">Share Idea</button>
        </div>
        <button id="generate-btn" class="btn-primary">Generate Prompt</button>

        <!-- Share Idea Modal -->
        <div id="share-modal" class="modal-overlay hidden">
            <div class="modal modal-small">
                <div class="modal-header">
                    <h3>Share Idea</h3>
                    <button id="btn-close-share" class="btn-modal-close">&times;</button>
                </div>
                <div class="modal-body">
                    <p>Share your idea as a prefilled Quality Prompts link.</p>
                    <div class="share-options">
                        <button id="share-url" class="btn-share-option">Copy link</button>
                        <button id="share-url-enter" class="btn-share-option">Copy link with auto-generate</button>
                    </div>
                    <div id="share-status" class="share-status hidden"></div>
                </div>
            </div>
        </div>

        <!-- Error -->
        <div id="error-section" class="error-message hidden"></div>

        <!-- Loading -->
        <div id="loading-section" class="loading-container hidden">
            <div class="spinner"></div>
            <div class="loading-text">Generating your prompt...</div>
            <div class="loading-status">Analyzing subject type, optimizing for target model</div>
            <div id="slow-hint" class="slow-hint hidden">
                Taking too long? <a href="#" id="slow-hint-link">Try a faster model</a>
            </div>
        </div>

        <!-- Speed Tip Modal -->
        <div id="speed-modal" class="modal-overlay hidden">
            <div class="modal modal-small">
                <div class="modal-header">
                    <h3>Switch to a faster model</h3>
                    <button id="btn-close-speed" class="btn-modal-close">&times;</button>
                </div>
                <div class="modal-body">
                    <p>The gpt-oss-120b model (117B parameters) produces the highest quality prompts but can take 30-60 seconds to respond. If speed is more important than quality, switch to the smaller model:</p>
                    <ol>
                        <li>Click <strong>API Settings</strong> at the top of the page</li>
                        <li>Under <strong>Model</strong>, select <strong>gpt-oss-20b (21B params, faster)</strong></li>
                        <li>Click <strong>Generate Prompt</strong> again</li>
                    </ol>
                    <p>The 20b model is roughly 2-3x faster with slightly lower quality. Both models are free through Puter.</p>
                </div>
            </div>
        </div>

        <!-- Output -->
        <div id="output-section" class="output-section hidden">
            <hr class="section-divider">
            <h3>Generated Prompt</h3>

            <div class="tab-bar">
                <button class="tab-btn active" data-tab="plain">Plain Text</button>
                <button class="tab-btn" data-tab="structured">Structured</button>
                <button class="tab-btn" data-tab="json">JSON</button>
            </div>

            <!-- Plain Text Tab -->
            <div class="tab-panel active" data-tab="plain">
                <div id="plain-content" class="plain-text-output"></div>
                <div class="btn-row">
                    <button class="btn-small btn-copy" data-target="plain-content">Copy</button>
                    <button class="btn-small btn-download" data-target="plain-content" data-format="txt">Download .txt</button>
                    <button class="btn-small" id="btn-share-email">Share via Email</button>
                </div>
            </div>

            <!-- Structured Tab -->
            <div class="tab-panel" data-tab="structured">
                <pre id="structured-content"></pre>
                <div class="btn-row">
                    <button class="btn-small btn-copy" data-target="structured-content">Copy</button>
                    <button class="btn-small btn-download" data-target="structured-content" data-format="txt">Download .txt</button>
                </div>
            </div>

            <!-- JSON Tab -->
            <div class="tab-panel" data-tab="json">
                <pre id="json-content"></pre>
                <div class="btn-row">
                    <button class="btn-small btn-copy" data-target="json-content">Copy</button>
                    <button class="btn-small btn-download" data-target="json-content" data-format="json">Download .json</button>
                </div>
            </div>

            <!-- Notes -->
            <div id="optimization-notes" class="optimization-notes hidden">
                <strong>Optimization Notes</strong>
                <span></span>
            </div>

            <div id="token-estimate" class="token-estimate hidden"></div>

            <!-- Open in model buttons -->
            <div class="open-in-section">
                <h4>Use this prompt</h4>
                <div class="open-in-row">
                    <button class="btn-open-in btn-chatgpt" data-service="chatgpt">Open in ChatGPT</button>
                    <button class="btn-open-in btn-claude" data-service="claude">Open in Claude</button>
                    <button class="btn-open-in btn-copilot" data-service="copilot">Open in Copilot</button>
                    <button class="btn-open-in btn-gemini" data-service="gemini">Open in Gemini</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Clipboard toast modal -->
    <div id="clipboard-modal" class="clipboard-modal hidden">
        <div class="clipboard-modal-content">
            <p id="clipboard-modal-text"></p>
        </div>
    </div>

    <footer class="license-section">
        <div class="footer-links">
            <div class="license-badge">
                MIT License
                <div class="license-tooltip">
                    MIT License<br><br>
                    Copyright (c) 2026 Austin Harshberger<br><br>
                    Permission is hereby granted, free of charge, to any person obtaining a copy
                    of this software and associated documentation files (the "Software"), to deal
                    in the Software without restriction, including without limitation the rights
                    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
                    copies of the Software, and to permit persons to whom the Software is
                    furnished to do so, subject to the following conditions:<br><br>
                    The above copyright notice and this permission notice shall be included in all
                    copies or substantial portions of the Software.
                </div>
            </div>
            <a href="https://attest.ink/verify/?data=eyJ2ZXJzaW9uIjoiMi4wIiwiaWQiOiIyMDI2LTAyLTE1LXF1YWxpdHlwcm9tcHRzIiwiY29udGVudF9uYW1lIjoiUXVhbGl0eSBQcm9tcHRzIiwidGltZXN0YW1wIjoiMjAyNi0wMi0xNVQwMDowMDowMC4wMDBaIiwicGxhdGZvcm0iOiJhdHRlc3QuaW5rIiwibW9kZWwiOiJjbGF1ZGUtb3B1cy00LTYiLCJyb2xlIjoiZ2VuZXJhdGVkIiwiZG9jdW1lbnRfdHlwZSI6ImNvZGUiLCJhdXRob3IiOiI5NyAxMTUgMTA0In0=" class="attest-badge" target="_blank" rel="noopener noreferrer">
                built with ai
            </a>
        </div>
        <div class="author-info">
            Created by Austin Harshberger
        </div>
    </footer>

    <script src="./js/promptEngine.js"></script>
    <script src="./js/apiClient.js"></script>
    <script src="./js/uiRenderer.js"></script>
    <script src="./js/app.js"></script>
</body>
</html>
